{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPc0tsC9yBmuYX83sqpJ637"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"bcWpunpd7GMF","executionInfo":{"status":"ok","timestamp":1762630408474,"user_tz":420,"elapsed":3044,"user":{"displayName":"Daniel Armando Ríos Rivera","userId":"03719866353312389752"}}},"outputs":[],"source":["!uv pip install -q --system numba-cuda==0.4.0\n","import numpy as np\n","from numba import cuda\n","import time\n","import os\n","from numba import config\n","config.CUDA_ENABLE_PYNVJITLINK = 1"]},{"cell_type":"code","source":["# CUDA Steps\n","# Initializing data from CPU\n","# Transefer from CPU to GPU\n","# Run Kernel with defined Grid/Block size (Threads)\n","# Transfer results from GPU to CPU\n","# Clear memory\n","\n","# CUDA kernel device\n","@cuda.jit\n","def first_kernel(a, result):\n","  idx = cuda.grid(1)\n","  if idx < a.size:\n","    result[idx] = a[idx]\n","\n","# Host\n","def main():\n","  # 1.- Initialize data on CPU\n","  N = 10_000_000\n","  a_cpu = np.arange(N, dtype=np.float32)\n","\n","  # ---------------\n","  # CPU computation\n","  # ---------------\n","  start = time.time()\n","  result_cpu = a_cpu\n","  cpu_time = time.time() - start\n","  print(f\"CPU time: {cpu_time * 1e3:.2f} ms\")\n","\n","  # ---------------\n","  #  GPU computation\n","  # ---------------\n","  # 2.- Tranfer from CPU to GPU\n","  start = time.time()\n","  a_gpu = cuda.to_device(a_cpu)\n","  result_gpu = cuda.device_array_like(a_cpu)  # Reserve memory\n","  transfer_in_time = time.time() - start\n","\n","  # Kernel launch\n","  threads_per_block = 128\n","  blocks_per_grid = (N + threads_per_block - 1) // threads_per_block  # (10_000_000 + 127) // 128\n","  start = time.time()\n","  first_kernel[blocks_per_grid, threads_per_block](a_gpu, result_gpu) # launch kernel\n","  cuda.synchronize()\n","  kernel_time = time.time() - start\n","\n","  # Copy back\n","  start = time.time()\n","  result_from_gpu = result_gpu.copy_to_host()\n","  cuda.synchronize()\n","  transfer_out_time = time.time() - start\n","\n","  # Report\n","  print(f\"GPU transfer to device: {transfer_in_time * 1e3:.2f} ms\")\n","  print(f\"GPU kernel execution:   {kernel_time * 1e3:.2f} ms\")\n","  print(f\"GPU transfer to host:   {transfer_out_time * 1e3:.2f} ms\")\n","  print(f\"Total GPU time:         {(transfer_in_time + kernel_time + transfer_out_time) * 1e3:.2f} ms\")\n","\n","  # Cleanup\n","  del a_gpu, result_gpu\n","  cuda.close()\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NX8hrxKT-CGy","executionInfo":{"status":"ok","timestamp":1762631824602,"user_tz":420,"elapsed":2284,"user":{"displayName":"Daniel Armando Ríos Rivera","userId":"03719866353312389752"}},"outputId":"6756ef85-edff-4e50-ffba-4ae0de30e3c5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU time: 0.00 ms\n","GPU transfer to device: 299.91 ms\n","GPU kernel execution:   1869.46 ms\n","GPU transfer to host:   14.65 ms\n","Total GPU time:         2184.02 ms\n"]}]}]}